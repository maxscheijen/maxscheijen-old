<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Robust Cross Validation for Data Science - Taxi Trip Duration | Max Scheijen</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Robust Cross Validation for Data Science - Taxi Trip Duration" />
<meta name="author" content="Max Scheijen" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="One of the first things you learn when applying machine learning models is the notion of cross-validation. Training a model, which basically is learning the parameters of a prediction function, and evaluating the performance of a model on the same dataset is a methodological mistake. The machine learning model could learn the labels of the data and reproduce them. However, this is not really what we want. If we then deploy the machine learning model on unseen data, we run the risk of predicting not anything useful. Our model has only learned the training data." />
<meta property="og:description" content="One of the first things you learn when applying machine learning models is the notion of cross-validation. Training a model, which basically is learning the parameters of a prediction function, and evaluating the performance of a model on the same dataset is a methodological mistake. The machine learning model could learn the labels of the data and reproduce them. However, this is not really what we want. If we then deploy the machine learning model on unseen data, we run the risk of predicting not anything useful. Our model has only learned the training data." />
<link rel="canonical" href="maxscheijen.github.io/2020-03-05-cross-validation-taxi-trip-duration" />
<meta property="og:url" content="maxscheijen.github.io/2020-03-05-cross-validation-taxi-trip-duration" />
<meta property="og:site_name" content="Max Scheijen" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-05T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Robust Cross Validation for Data Science - Taxi Trip Duration" />
<meta name="twitter:site" content="@maxscheijen" />
<meta name="twitter:creator" content="@Max Scheijen" />
<script type="application/ld+json">
{"url":"maxscheijen.github.io/2020-03-05-cross-validation-taxi-trip-duration","headline":"Robust Cross Validation for Data Science - Taxi Trip Duration","dateModified":"2020-03-05T00:00:00+01:00","datePublished":"2020-03-05T00:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"maxscheijen.github.io/2020-03-05-cross-validation-taxi-trip-duration"},"author":{"@type":"Person","name":"Max Scheijen"},"description":"One of the first things you learn when applying machine learning models is the notion of cross-validation. Training a model, which basically is learning the parameters of a prediction function, and evaluating the performance of a model on the same dataset is a methodological mistake. The machine learning model could learn the labels of the data and reproduce them. However, this is not really what we want. If we then deploy the machine learning model on unseen data, we run the risk of predicting not anything useful. Our model has only learned the training data.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="maxscheijen.github.io/feed.xml" title="Max Scheijen" />
</head>
<body>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']],
          processEscapes: true
        }
      });
      </script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Max Scheijen</a><nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path
              d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z" />
          </svg>
        </span>
      </label>

      <div class="trigger"><a class="page-link" href="/about/">About</a>
        <a class="page-link" href="https://twitter.com/maxscheijen" target="_blank">Twitter</a>
        <a class="page-link" href="https://github.com/maxscheijen" target="_blank">Github</a>
        <a class="page-link" href="/feed.xml" target="_blank">Subscribe</a>
        <a class="page-link" href="/archive">Archive</a></div>
    </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Robust Cross Validation for Data Science - Taxi Trip Duration</h1>
    <p class="post-meta"><time class="dt-published" datetime="2020-03-05T00:00:00+01:00" itemprop="datePublished">
        Mar 5, 2020
      </time>
      <span>• 

  
    7 min read
  

</span>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Max Scheijen</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>One of the first things you learn when applying machine learning models is the notion of cross-validation. Training a model, which basically is learning the parameters of a prediction function, and evaluating the performance of a model on the same dataset is a methodological mistake. The machine learning model could learn the labels of the data and reproduce them. However, this is not really what we want. If we then deploy the machine learning model on unseen data, we run the risk of predicting not anything useful. Our model has only learned the training data.</p>

<p>In this post, I present a robust cross-validation method for tabular data. This method, among other things, can be used in Data Science competitions.</p>

<p>To demonstrate this technique, we use the <a href="https://www.kaggle.com/c/nyc-taxi-trip-duration/overview" target="_blank">New York City Taxi Trip Duration</a> competition hosted on <a href="https://www.kaggle.com/" target="_blank">Kaggle</a>. In this competition, we try to predict the trip duration.</p>

<p>This post is not intended to achieve a high score in the competition in question. I  demonstrate a way to implement a cross-validation method that gives the same results on validation data as on unseen test data.</p>

<div class="alert" style="background-color: #f6f6f6">
  <strong>Note: </strong> This methods is heavily based on <a href="https://twitter.com/abhi1thakur" target="_blank">Abhishek Thakur</a> cross validation method.
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># load data
</span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/train.csv'</span><span class="p">).</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">,</span> <span class="s">'dropoff_datetime'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/test.csv'</span><span class="p">).</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># display first 3 rows
</span><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vendor_id</th>
      <th>pickup_datetime</th>
      <th>passenger_count</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>store_and_fwd_flag</th>
      <th>trip_duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>2016-03-14 17:24:55</td>
      <td>1</td>
      <td>-73.982155</td>
      <td>40.767937</td>
      <td>-73.964630</td>
      <td>40.765602</td>
      <td>N</td>
      <td>455</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2016-06-12 00:43:35</td>
      <td>1</td>
      <td>-73.980415</td>
      <td>40.738564</td>
      <td>-73.999481</td>
      <td>40.731152</td>
      <td>N</td>
      <td>663</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2016-01-19 11:35:24</td>
      <td>1</td>
      <td>-73.979027</td>
      <td>40.763939</td>
      <td>-74.005333</td>
      <td>40.710087</td>
      <td>N</td>
      <td>2124</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="k-fold-cross-validation">$k$-fold cross-validation</h2>

<p>We load the train and test data into the cell above. I drop the <code class="language-plaintext highlighter-rouge">dropoff_datetime</code> because this feature isn’t present in the testing data.</p>

<p>We use $k$-fold cross-validation to implement our cross-validation method. In $k$-fold cross-validation we estimate what our model has learned based on new data that the model has not yet seen. The $k$ in $k$-fold cross-validation shows how many groups we divide our data into. If $k$ = 5 then we divide our data into 5 groups. We then train our algorithm on 4 groups of the data, and we validate the model on the 1 group of data that the model has not yet seen. We repeat this process until we have trained our model on each group of data once. Also, each group of data has been used to validate our model.</p>

<p>To implement this method we use <code class="language-plaintext highlighter-rouge">sklearn</code>’s $k$-fold cross-validation capabilities. In our case, we are dealing with a regression problem. This is why we use a simple k-fold method. However, if you are dealing with a classification problem you can use stratified $k$-fold cross-validation. This ensures that the frequency of labels between the folds is the same. And increases ensures better consistency between validation and testing scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># number of folds used
</span><span class="n">FOLDS</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># instantiate k-fold cross-validation
</span><span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">FOLDS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>In this case choose $k$ = 5. We have a relatively large data set, so it seems to me that 5 folds will generate a robust validation score. We are now going to divide our data into 5 groups/folds. We create a new column in which we record the fold the observation belongs to.</p>

<p>However, before we do this, we randomize the order of the data. This way, we prevent the order in which the data is placed from becoming important, which can incorporate bias in our validation score.</p>

<div class="alert" style="background-color: #f6f6f6">
  <strong>Note: </strong>  don't do this with a time series. Use sklearn's dedicated time series cross validation functionality.
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># randomize order of dataframe
</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># create fold columns and store the fold
</span><span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kfold</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="s">'trip_duration'</span><span class="p">])):</span>
    <span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">,</span> <span class="s">'kfold'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold</span>

<span class="c1"># display rows
</span><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vendor_id</th>
      <th>pickup_datetime</th>
      <th>passenger_count</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>store_and_fwd_flag</th>
      <th>trip_duration</th>
      <th>kfold</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>2016-02-27 20:13:05</td>
      <td>1</td>
      <td>-73.981728</td>
      <td>40.749500</td>
      <td>-73.945915</td>
      <td>40.792061</td>
      <td>N</td>
      <td>692</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2016-06-04 09:54:05</td>
      <td>1</td>
      <td>-73.979088</td>
      <td>40.771606</td>
      <td>-73.946518</td>
      <td>40.822655</td>
      <td>N</td>
      <td>990</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2016-05-06 17:40:05</td>
      <td>1</td>
      <td>-73.989700</td>
      <td>40.738651</td>
      <td>-73.997772</td>
      <td>40.754051</td>
      <td>N</td>
      <td>647</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now we have created a column in which we record the fold the observation belongs to. If we look at the size distribution of the number of folds, we see that the folds are approximately the same. This is what we want!</p>

<p>Sometimes there can be a small difference in the number of observations (in our case!) because the number of recorded samples is not easily divisible by the number of folds.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># size of every fold
</span><span class="n">train</span><span class="p">[</span><span class="s">'kfold'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0    291729
3.0    291729
2.0    291729
0.0    291729
4.0    291728
Name: kfold, dtype: int64
</code></pre></div></div>

<p>Even though this post does not focus on creating a well-performing predictive model, I’ll do simple feature engineering to make the performance of our model a little bit better. This makes me feel a little bit better about myself! The function below extracts some simple date features from the date feature. This also gives us some more variables to work with.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract_dates</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">date_column</span><span class="p">):</span>
    <span class="c1"># get datetime index
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DatetimeIndex</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">date_column</span><span class="p">])</span>

    <span class="c1"># create date features
</span>    <span class="n">data</span><span class="p">[</span><span class="s">'year'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'month'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'week'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'hour'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'minute'</span><span class="p">]</span> <span class="o">=</span>\
    <span class="n">d</span><span class="p">.</span><span class="n">year</span><span class="p">,</span> <span class="n">d</span><span class="p">.</span><span class="n">month</span><span class="p">,</span> <span class="n">d</span><span class="p">.</span><span class="n">week</span><span class="p">,</span> <span class="n">d</span><span class="p">.</span><span class="n">dayofweek</span><span class="p">,</span> <span class="n">d</span><span class="p">.</span><span class="n">hour</span><span class="p">,</span> <span class="n">d</span><span class="p">.</span><span class="n">minute</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="n">date_column</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># extract date features
</span><span class="n">train</span> <span class="o">=</span> <span class="n">extract_dates</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s">'pickup_datetime'</span><span class="p">)</span>

<span class="c1"># display
</span><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>vendor_id</th>
      <th>passenger_count</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>store_and_fwd_flag</th>
      <th>trip_duration</th>
      <th>kfold</th>
      <th>year</th>
      <th>month</th>
      <th>week</th>
      <th>dayofweek</th>
      <th>hour</th>
      <th>minute</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>-73.981728</td>
      <td>40.749500</td>
      <td>-73.945915</td>
      <td>40.792061</td>
      <td>N</td>
      <td>692</td>
      <td>0.0</td>
      <td>2016</td>
      <td>2</td>
      <td>8</td>
      <td>5</td>
      <td>20</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>-73.979088</td>
      <td>40.771606</td>
      <td>-73.946518</td>
      <td>40.822655</td>
      <td>N</td>
      <td>990</td>
      <td>0.0</td>
      <td>2016</td>
      <td>6</td>
      <td>22</td>
      <td>5</td>
      <td>9</td>
      <td>54</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>-73.989700</td>
      <td>40.738651</td>
      <td>-73.997772</td>
      <td>40.754051</td>
      <td>N</td>
      <td>647</td>
      <td>0.0</td>
      <td>2016</td>
      <td>5</td>
      <td>18</td>
      <td>4</td>
      <td>17</td>
      <td>40</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="model-training-using-k-folds">Model training using $k$-folds</h2>

<p>We are now switching to training our machine learning model on our 5 folds. This means that we get as many models as folds, in this case, we’ll end up with 5 different models.</p>

<p>We create a function that allows us to grab a specific fold of the training data set. This will be our validation dataset! Then the remaining folds become our training set on which we’ll train the model. It also lets us define the fold we want to validate our model on.  Furthermore, we can choose to drop certain variables. We always want to remove the <code class="language-plaintext highlighter-rouge">k-fold</code> variable because this feature is not present in the testing data. This variable does not provide any predictive information.</p>

<p>As an example of the validation and and training fold:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FOLD <span class="o">=</span> 0 - VALIDATION FOLD <span class="o">=</span> 0 - TRAINING FOLD <span class="o">=</span> <span class="o">[</span>1, 2, 3, 4]
FOLD <span class="o">=</span> 1 - VALIDATION FOLD <span class="o">=</span> 1 - TRAINING FOLD <span class="o">=</span> <span class="o">[</span>0, 2, 3, 4]
FOLD <span class="o">=</span> 2 - VALIDATION FOLD <span class="o">=</span> 2 - TRAINING FOLD <span class="o">=</span> <span class="o">[</span>1, 0, 3, 4]
FOLD <span class="o">=</span> 3 - VALIDATION FOLD <span class="o">=</span> 3 - TRAINING FOLD <span class="o">=</span> <span class="o">[</span>1, 2, 0, 4]
FOLD <span class="o">=</span> 4 - VALIDATION FOLD <span class="o">=</span> 4 - TRAINING FOLD <span class="o">=</span> <span class="o">[</span>1, 2, 3, 0]
</code></pre></div></div>

<p>We then return our dataset with training features (<code class="language-plaintext highlighter-rouge">X_train</code>), validation features (<code class="language-plaintext highlighter-rouge">X_valid</code>), our training target values (<code class="language-plaintext highlighter-rouge">y_train</code>), and our validation targets (<code class="language-plaintext highlighter-rouge">y_valid</code>).</p>

<p><strong>NOTE</strong>: In this case, I log-transform the target feature for better predictive performance. This is problem specific.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_folds</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">drop_features</span><span class="p">,</span> <span class="n">fold</span><span class="p">):</span>

    <span class="c1"># get training folds and validation fold
</span>    <span class="n">train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">kfold</span> <span class="o">!=</span> <span class="n">fold</span><span class="p">].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">kfold</span> <span class="o">==</span> <span class="n">fold</span><span class="p">].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># extract targets
</span>    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
    <span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>

    <span class="c1"># features that need to be dropped
</span>    <span class="n">feat_to_drop</span>  <span class="o">=</span> <span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">+</span> <span class="n">drop_features</span>

    <span class="c1"># drop features in train data
</span>    <span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">feat_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># make validation features equal to train features
</span>    <span class="n">X_valid</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span>  
</code></pre></div></div>

<p>As a demonstration, we use a random forest machine learning model to predict our target variable. However, you can use any machine learning model here. I set a random state for reproducibility.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">MODEL</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We then create a new function that takes a model and the number of folds. The model is then trained on the training folds data and validated on the validation folds. For every fold, we save the trained model as a pickle file in the models’ directory.</p>

<p>We also store names of the features on which the model is trained. We can use these features later to select variables from the test set. When there are categorical variables in your dataset, or you need to impute missing data,  also save this transformation based on the folds. This ensures that we can apply the same transformations to the train, validation, and testing data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">train_folds</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">folds</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># loop over number of folds
</span>    <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">folds</span><span class="p">):</span>

        <span class="c1"># get train and validation folds
</span>        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">get_folds</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'trip_duration'</span><span class="p">,</span> <span class="p">[</span><span class="s">'kfold'</span><span class="p">],</span> <span class="n">fold</span><span class="p">)</span>

        <span class="c1"># fitting label encoding on train, validation and testing data
</span>        <span class="n">enc_feature</span> <span class="o">=</span> <span class="s">'store_and_fwd_flag'</span>

        <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>

        <span class="n">le</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X_train</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">],</span> <span class="n">X_valid</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">]]))</span>

        <span class="n">X_train</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">])</span>
        <span class="n">X_valid</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_valid</span><span class="p">[</span><span class="n">enc_feature</span><span class="p">])</span>

        <span class="c1"># train on train folds
</span>        <span class="n">m</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">m</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># get prediction on valid fold
</span>        <span class="n">valid_pred</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>

        <span class="c1"># print score metric
</span>        <span class="n">valid_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">valid_pred</span><span class="p">))</span>
        <span class="n">scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_score</span><span class="p">)</span>

        <span class="c1"># print fold model score
</span>        <span class="k">print</span><span class="p">(</span><span class="s">f"FOLD: </span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s"> - RMSLE: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_score</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="c1"># save model, features and label encoding
</span>        <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s">f"models/MODEL_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json"</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="s">f"models/FEAT_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json"</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">le</span><span class="p">,</span> <span class="s">f"models/ENC_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json"</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># print mean score
</span>    <span class="k">print</span><span class="p">(</span><span class="s">f"</span><span class="se">\n</span><span class="s">Mean RMSLE: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">):.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">):.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">)"</span><span class="p">)</span>

<span class="n">train_folds</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">FOLDS</span><span class="p">,</span> <span class="n">MODEL</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FOLD: 0 - RMSLE: 0.432
FOLD: 1 - RMSLE: 0.4351
FOLD: 2 - RMSLE: 0.4286
FOLD: 3 - RMSLE: 0.4363
FOLD: 4 - RMSLE: 0.4326

Mean RMSLE: 0.4329 <span class="o">(</span>0.0027<span class="o">)</span>
</code></pre></div></div>

<h2 id="making-predictions-using-folds">Making predictions using folds</h2>

<p>We can now use the 5 models that we trained and saved to make predictions about our test data. We can then take the average of these 5 predictions and use this as our final prediction.</p>

<p>Before we do this, we first create a new data frame with 5 columns to store our 5 test data predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># generate column names
</span><span class="n">folds_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">f"FOLD_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">FOLDS</span><span class="p">)]</span>

<span class="c1"># create empty dataframe
</span><span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">),</span> <span class="n">FOLDS</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="n">folds_columns</span><span class="p">)</span>

<span class="c1"># display empty dataframe
</span><span class="n">pred_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FOLD_0</th>
      <th>FOLD_1</th>
      <th>FOLD_2</th>
      <th>FOLD_3</th>
      <th>FOLD_4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>We now loop over every fold and load the model, the features files, and the encoding that corresponds to the specific fold. Each of these models then makes a prediction on the test data columns after apply label encoding. We store this prediction in the relevant column of the new data frame.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># loop over folds
</span><span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">FOLDS</span><span class="p">):</span>

    <span class="c1"># load test data
</span>    <span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/test.csv'</span><span class="p">).</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># create date features
</span>    <span class="n">test</span> <span class="o">=</span> <span class="n">extract_dates</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="s">'pickup_datetime'</span><span class="p">)</span>

    <span class="c1"># load label encoder and transform test feature
</span>    <span class="n">encoder</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">f'models/ENC_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json'</span><span class="p">)</span>

    <span class="n">test</span><span class="p">[</span><span class="s">'store_and_fwd_flag'</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'store_and_fwd_flag'</span><span class="p">])</span>

    <span class="c1"># load fold model
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">f'models/MODEL_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json'</span><span class="p">)</span>

    <span class="c1"># load fold features
</span>    <span class="n">feat</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">f'models/FEAT_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">.json'</span><span class="p">)</span>

    <span class="c1"># predict on test data
</span>    <span class="n">pred</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">feat</span><span class="p">])</span>

    <span class="c1"># store predictions in fold column
</span>    <span class="n">pred_df</span><span class="p">[</span><span class="s">f"FOLD_</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="n">pred_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FOLD_0</th>
      <th>FOLD_1</th>
      <th>FOLD_2</th>
      <th>FOLD_3</th>
      <th>FOLD_4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>628.423460</td>
      <td>716.639654</td>
      <td>815.767972</td>
      <td>728.653350</td>
      <td>883.245895</td>
    </tr>
    <tr>
      <th>1</th>
      <td>553.966449</td>
      <td>639.652247</td>
      <td>622.347987</td>
      <td>668.222903</td>
      <td>671.115124</td>
    </tr>
    <tr>
      <th>2</th>
      <td>672.211223</td>
      <td>510.996218</td>
      <td>563.263305</td>
      <td>395.760266</td>
      <td>506.161285</td>
    </tr>
  </tbody>
</table>
</div>

<p>We can then take the average prediction of these five models as our final prediction.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the mean of k predictions
</span><span class="n">final_preds</span> <span class="o">=</span> <span class="n">pred_df</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># display first 3 rows
</span><span class="n">final_preds</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    754.546066
1    631.060942
2    529.678459
dtype: float64
</code></pre></div></div>

<p>We store this average prediction in our submission file and upload it to Kaggle to get our testing score. Our testing score on Kaggle is <strong>0.41885</strong>. The internal mean validation score was <strong>0.4329</strong>, which isn’t too bad of a difference.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load sample submission
</span><span class="n">sample_sub</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/sample_submission.csv'</span><span class="p">)</span>

<span class="c1"># store predictions in column
</span><span class="n">sample_sub</span><span class="p">[</span><span class="s">'trip_duration'</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_preds</span>

<span class="c1"># save predictions
</span><span class="n">sample_sub</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'submissions/submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, I demonstrated a simple way to use cross-validation to train a model on folds and use those folds to predict on unseen test data. This results in a cross-validation and testing score that are relatively close to each other.</p>

  </div><a class="u-url" href="/2020-03-05-cross-validation-taxi-trip-duration" hidden></a>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
    </div>
  </div>

</footer></body>

</html>
