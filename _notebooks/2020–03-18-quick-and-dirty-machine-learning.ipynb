{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick and Dirty Machine Learning: Modeling Earthquake Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I would like to demonstrate a quick way to create a good performing machine learning model. It is often encouraging to get a good performing model fast, without major pre-processing and featuring engineering. After this, we can use model selection, hyper-parameter tweaking, and feature engineering to squeeze out a little more predictive performance. However, it is really encouraging to get a well-performing fast.\n",
    "\n",
    "So let's get started! I will be using data from a Data Science competition to asses the model's performance. The contest is called <a href=\"https://www.drivendata.org/competitions/57/nepal-earthquake/\">\"Richter's Predictor: Modeling Earthquake Damage\"</a> hosted by <a href=\"https://www.drivendata.org/\" target=\"_blank\">DrivenData</a>. The goal is to predict the damage to buildings caused by an earthquake. The amount of damage is divided into 3 categories:  (1) low, (2) medium, (3) almost complete destruction.\n",
    "\n",
    "In the cell below, we load the train values, train labels, test values, and the sample submission file and display the first couple of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  age  \\\n",
       "0               6             487           12198                    2   30   \n",
       "1               8             900            2812                    2   10   \n",
       "\n",
       "   area_percentage  height_percentage land_surface_condition foundation_type  \\\n",
       "0                6                  5                      t               r   \n",
       "1                8                  7                      o               r   \n",
       "\n",
       "  roof_type ground_floor_type other_floor_type position plan_configuration  \\\n",
       "0         n                 f                q        t                  d   \n",
       "1         n                 x                q        s                  d   \n",
       "\n",
       "   has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "0                             1                                    1   \n",
       "1                             0                                    1   \n",
       "\n",
       "   has_superstructure_stone_flag  has_superstructure_cement_mortar_stone  \\\n",
       "0                              0                                       0   \n",
       "1                              0                                       0   \n",
       "\n",
       "   has_superstructure_mud_mortar_brick  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "\n",
       "   has_superstructure_cement_mortar_brick  has_superstructure_timber  \\\n",
       "0                                       0                          0   \n",
       "1                                       0                          0   \n",
       "\n",
       "   has_superstructure_bamboo  has_superstructure_rc_non_engineered  \\\n",
       "0                          0                                     0   \n",
       "1                          0                                     0   \n",
       "\n",
       "   has_superstructure_rc_engineered  has_superstructure_other  \\\n",
       "0                                 0                         0   \n",
       "1                                 0                         0   \n",
       "\n",
       "  legal_ownership_status  count_families  has_secondary_use  \\\n",
       "0                      v               1                  0   \n",
       "1                      v               1                  0   \n",
       "\n",
       "   has_secondary_use_agriculture  has_secondary_use_hotel  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "\n",
       "   has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "\n",
       "   has_secondary_use_school  has_secondary_use_industry  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "\n",
       "   has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "\n",
       "   has_secondary_use_use_police  has_secondary_use_other  \n",
       "0                             0                        0  \n",
       "1                             0                        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(\"data/train_labels.csv\").drop('building_id', axis=1)\n",
    "train_values = pd.read_csv(\"data/train_values.csv\").drop('building_id', axis=1)\n",
    "\n",
    "test_values = pd.read_csv(\"data/test.csv\").drop('building_id', axis=1)\n",
    "sample_sub = pd.read_csv(\"data/submission_format.csv\")\n",
    "\n",
    "train_values.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things you should when dealing with classification is to look at the distribution of classes. For this, I use pandas value_count capabilities to get the frequency distribution of the target labels. Not all target categories are equally present. \n",
    "\n",
    "Label 2 is the majority class, with 56% of the observations. This percentage will be our baseline score. We need to outperform this score for our model to add something valuable. Otherwise, we would be better of always predicting label 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.096408\n",
       "2    0.568912\n",
       "3    0.334680\n",
       "Name: damage_grade, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.damage_grade.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only preprocessing we'll do is to get the data ready for the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often machine learning models don't allow for missing values in our data. We should identify these values and treat them. In our specific case, we are lucky because we don't have any missing values. However, if we would encounter them, these values need to be replaced. \n",
    "\n",
    "A good starting point is replacing missing numerical values with the mean or median, and replacing missing categorical values with the most frequent (mode) value. Note that your method of imputing missing values can have an impact on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.isna().sum().sum(), test_values.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, machine learning models also don't allow for categorical variables. We need to identify these features and encode them. One important note is that there should be consistency between the numerical representation of these values in the features in the train and test set.  \n",
    "\n",
    "This can be achieved by first concatenating the test data at the end of the train data. Secondly, we encode the categorical features, after which we split the data back into a train and test set. We now have a constant representation of these variables between our train and test set.\n",
    "\n",
    "Label encoding is a good starting point. This method encodes features with a value between 0 and n_classes-1. This technique works best with ordinal features because it implies ordering. However, because this post is about getting a quick model done, we apply it to all categorical features. We use some assert statements to test if the shape of the original train and test set are the same as the encoded ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  age  \\\n",
       "0               6             487           12198                    2   30   \n",
       "1               8             900            2812                    2   10   \n",
       "2              21             363            8973                    2   10   \n",
       "\n",
       "   area_percentage  height_percentage  land_surface_condition  \\\n",
       "0                6                  5                       2   \n",
       "1                8                  7                       1   \n",
       "2                5                  5                       2   \n",
       "\n",
       "   foundation_type  roof_type  ground_floor_type  other_floor_type  position  \\\n",
       "0                2          0                  0                 1         3   \n",
       "1                2          0                  3                 1         2   \n",
       "2                2          0                  0                 3         3   \n",
       "\n",
       "   plan_configuration  has_superstructure_adobe_mud  \\\n",
       "0                   2                             1   \n",
       "1                   2                             0   \n",
       "2                   2                             0   \n",
       "\n",
       "   has_superstructure_mud_mortar_stone  has_superstructure_stone_flag  \\\n",
       "0                                    1                              0   \n",
       "1                                    1                              0   \n",
       "2                                    1                              0   \n",
       "\n",
       "   has_superstructure_cement_mortar_stone  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "\n",
       "   has_superstructure_mud_mortar_brick  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "\n",
       "   has_superstructure_cement_mortar_brick  has_superstructure_timber  \\\n",
       "0                                       0                          0   \n",
       "1                                       0                          0   \n",
       "2                                       0                          0   \n",
       "\n",
       "   has_superstructure_bamboo  has_superstructure_rc_non_engineered  \\\n",
       "0                          0                                     0   \n",
       "1                          0                                     0   \n",
       "2                          0                                     0   \n",
       "\n",
       "   has_superstructure_rc_engineered  has_superstructure_other  \\\n",
       "0                                 0                         0   \n",
       "1                                 0                         0   \n",
       "2                                 0                         0   \n",
       "\n",
       "   legal_ownership_status  count_families  has_secondary_use  \\\n",
       "0                       2               1                  0   \n",
       "1                       2               1                  0   \n",
       "2                       2               1                  0   \n",
       "\n",
       "   has_secondary_use_agriculture  has_secondary_use_hotel  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "\n",
       "   has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "\n",
       "   has_secondary_use_school  has_secondary_use_industry  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "\n",
       "   has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "\n",
       "   has_secondary_use_use_police  has_secondary_use_other  \n",
       "0                             0                        0  \n",
       "1                             0                        0  \n",
       "2                             0                        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "all_data = pd.concat([train_values, test_values])\n",
    "categorical_features = all_data.select_dtypes('object').columns\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "all_data[categorical_features] = all_data[categorical_features].apply(label_encoder.fit_transform)\n",
    "\n",
    "train_enc = all_data[:len(train_values)]\n",
    "test_enc = all_data[len(train_values):]\n",
    "\n",
    "assert train_enc.shape == train_values.shape \n",
    "assert test_enc.shape == test_values.shape\n",
    "\n",
    "train_enc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our model, we should create a validation dataset. This lets us internally test our model, before predicting the test data. We're dealing with a classification problem, with an uneven class distribution. Therefore we should us stratification when splitting our data into a train and validation sets. This ensures that we have the same class distribution in our train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_enc\n",
    "y = train_labels\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is all done, we can start training our machine learning model. We use a LightGBM, which is a gradient boosting framework that uses tree-based learning algorithms. According to the developers, it is designed to be distributed and efficient with the following advantages:\n",
    "\n",
    "* Faster training speed and higher efficiency.\n",
    "* Lower memory usage.\n",
    "* Better accuracy.\n",
    "* Support for parallel and GPU learning.\n",
    "* Capable of handling large-scale data.\n",
    "\n",
    "A basic LightGBM model can be trained in the same way as you fit a scikit-learn machine learning model. We start with 200 estimators, max depth of 50 with 900 leaves. This model only takes about a minute to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 2.76 s, total: 3min 10s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(random_state=1, n_estimators=200, max_depth=50, num_leaves=900)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we use the **micro averaged f1 score**, the same as in the contest. Our model gives us an f1-micro averaged score of **0.7422**, which is quite good. Especially when you keep in mind that we did so little processing and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "score_model = f1_score(y_valid, preds, average='micro')\n",
    "round(score_model, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does outperform the naive majority class which gets a micro f1-score of **0.5689**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5689"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_pred = np.zeros((len(y_valid))) + 2\n",
    "score_naive = f1_score(y_valid, naive_pred, average='micro')\n",
    "round(score_naive, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the full model and predicting on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train on the full dataset, which also lets us train on the validation set. After this, we can make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 45s, sys: 3.1 s, total: 3min 48s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X, y)\n",
    "test_preds = model.predict(test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the test dataset predictions in the damage_grade columns of the sample submission file and save it as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['damage_grade'] = test_preds\n",
    "sample_sub.to_csv(\"prediction.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting to the competition, we a score of **0.7446**. As of 2020-03-18, this ranks us in the top **6-7%** of the leaderboard. This post demonstrated that we can achieve quite good performing models with almost no preprocessing, by leveraging the power of the LightGBM machine learning framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
